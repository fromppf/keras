{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "oxford deepNLP 2017 practical 2.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/fromppf/keras/blob/master/oxford_deepNLP_2017_practical_2.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "rgADmJxnjJ0f",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Practical 2: Text Classification\n",
        "Practical 2: Text Classification\n",
        "[Chris Dyer, Yannis Assael, Brendan Shillingford]\n",
        "\n",
        "TED stands for “Technology, Entertainment, and Design”. Each talk in the corpus is labeled with a series of open labels by annotators, including the labels “technology”, “entertainment”, and “design”. Although some talks are about more than one of these, and about half aren’t labeled as being about any of them! In this assignment, you will build a text classification model that predicts whether a talk is about technology, entertainment, or design--or none of these.\n",
        "\n",
        "This is an instance of what is called “multi-label classification” (MLC), where each instance may have many different labels. However, we will start off by converting it into an instance of multi-class classification, where each document receives a single label from a finite discrete set of possible labels.\n",
        "\n",
        "#### Setup and installation\n",
        "To answer the following questions you are allowed to use any machine learning framework of your taste. The practical demonstrators can provide help for:\n",
        "\n",
        "* PyTorch (example for regression)\n",
        "* TensorFlow (example for logistic regression)\n",
        "Other suggested frameworks: CNTK, Torch, Caffe.\n",
        "\n",
        "#### Multi-class classification\n",
        "##### Data preparation\n",
        "You should reserve the first 1585 documents of the TED talks dataset for training, the subsequent 250 for validation, and the final 250 for testing. Each document will be represented as a pairs of (text, label).\n",
        "\n",
        "###### Text of talks\n",
        "Using the training data, you should determine what vocabulary you want for your model. A good rule of thumb is to tokenise and lowercase the text (you did this in the intro practical).\n",
        "\n",
        "At test time, you will encounter words that were not present in the training set (and they will therefore not have an embedding). To deal with this, map these words to a special token. You will also want to ensure that your training set contains tokens.\n",
        "\n",
        "###### Labels\n",
        "Each document should be labeled with label from the set: {Too, oEo, ooD, TEo, ToD, oED, TED, ooo}. You are called to generate labels from the <keywords> tag by checking the existence of one of the following tags: {Technology, Entertainment, Design}.\n",
        "\n",
        "* None of the keywords → ooo\n",
        "* “Technology” → Too\n",
        "* “Entertainment” → oEo\n",
        "* “Design” → ooD\n",
        "* “Technology” and “Entertainment” → TEo\n",
        "* “Technology” and “Design” → ToD\n",
        "* “Entertainment” and “Design” → oED\n",
        "* “Technology” and “Entertainment” and “Design” → TED\n",
        "\n",
        "###### Model\n",
        "A simple multilayer perceptron classifier operates as follows:\n",
        "\n",
        "x = embedding(text)\n",
        "h = tanh(Wx + b)\n",
        "u = Vh + c\n",
        "p = softmax(u)\n",
        "if testing:\n",
        "    prediction = arg maxy’ py’\n",
        "else: # training, with y as the given gold label\n",
        "    loss = -log(py) # cross entropy criterion\n",
        "\n",
        "We will discuss the embedding function that represents the text as a vector (x) is discussed below. W and V are appropriately sized matrices of learned parameters, b and c are learned bias vectors. The other vectors are intermediate values.\n",
        "\n",
        "###### Text embedding function\n",
        "The text embedding function converts a sequence of words into a fixed sized vector representation. Effective models for representing documents as vectors is an open area of research, but in general, trying a few different architectures is important since the optimal architecture depends both on the availability of data and the nature of the problem being solved.\n",
        "\n",
        "* An astoundingly simple but effective embedding model is the “bag-of-means” representation. Let each word wi in the document (where i ranges over the tokens) be represented by an embedding vector xi. The bag of means representation is\n",
        "#######    x = (1/N) sumi xi.\n",
        "Word embeddings can be learned as parameters in the model (either starting from random values or starting from a word embedding model, such as word2vec or GloVe), or they you can use fixed values (again, word2vec or Glove).\n",
        "\n",
        "* A more sophisticated model uses an bidirectional RNN (/LSTM/GRU) to “read” the document (from left to right and from right to left), and then represents the document by pooling the hidden states across time (e.g., by simply taking their arithmetic average or componentwise maximum) and using that as the document vector. You can explore this next week for your practical assignment on RNNs.\n",
        "\n",
        "#### Questions\n",
        "You are called to build a single-layer feed-forward neural network in your favourite framework. The network should treat the labels as 8 independent classes. We suggest Adam as optimiser, and training should place in batches for increased stability (e.g.~50).\n",
        "\n",
        "1. Compare the learning curves of the model starting from random embeddings, starting from GloVe embeddings (http://nlp.stanford.edu/data/glove.6B.zip; 50 dimensions) or fixed to be the GloVe values. Training in batches is more stable (e.g. 50), which model works best on training vs. test? Which model works best on held-out accuracy?\n",
        "2. What happens if you try alternative non-linearities (logistic sigmoid or ReLU instead of tanh)?\n",
        "3. What happens if you add dropout to the network?\n",
        "4. What happens if you vary the size of the hidden layer?\n",
        "5. How would the code change if you wanted to add a second hidden layer?\n",
        "6. How does the training algorithm affect the quality of the model?\n",
        "7. Project the embeddings of the labels onto 2 dimensions and visualise (each row of the projection matrix V corresponds a label embedding). Do you see anything interesting?\n",
        "\n",
        "##### (Optional, for enthusiastic students)\n",
        "Try the same prediction task using a true multi-label classification (MLC) set up.\n",
        "\n",
        "1. One common approach is to make a bunch of binary classification decisions (one for each label).\n",
        "2. Note, however, that separate binary classification problems don't model correlation structure. It may be the case that, for sake of argument, the label sequence \"ooD\" never occurs in the data, but we do not know that aprior when designing the model. MLC is an interesting problem in its own right (the name of the game is modeling label decisions jointly, exploiting correlation structure between them), and neural networks offer some really interesting possibilities for modeling MLC problems that have yet to be adequately explored in the literature. You may want to try adding a CRF at the output, for example.\n",
        "\n",
        "##### Handin\n",
        "On paper, show a practical demonstrator your response to these to get signed off.\n",
        "\n",
        "#### Step 0: Dependencies"
      ]
    },
    {
      "metadata": {
        "id": "-gGMpdqHJWJ0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        },
        "outputId": "163e8bfc-5762-4e09-b606-9a6aad55f76a"
      },
      "cell_type": "code",
      "source": [
        "#!pip install gensim\n",
        "#!pip install lxml\n",
        "#!pip install bokeh"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting bokeh\n",
            "  Downloading https://files.pythonhosted.org/packages/ad/67/82f17df7d1f4b9e81c9263c1a1dc3897c43cf5a9461872f9054517331f77/bokeh-0.12.15.tar.gz (13.6MB)\n",
            "\u001b[K    100% |████████████████████████████████| 13.6MB 94kB/s \n",
            "\u001b[?25hRequirement already satisfied: Jinja2>=2.7 in /usr/local/lib/python3.6/dist-packages (from bokeh)\n",
            "Requirement already satisfied: PyYAML>=3.10 in /usr/local/lib/python3.6/dist-packages (from bokeh)\n",
            "Requirement already satisfied: numpy>=1.7.1 in /usr/local/lib/python3.6/dist-packages (from bokeh)\n",
            "Collecting packaging>=16.8 (from bokeh)\n",
            "  Downloading https://files.pythonhosted.org/packages/ad/c2/b500ea05d5f9f361a562f089fc91f77ed3b4783e13a08a3daf82069b1224/packaging-17.1-py2.py3-none-any.whl\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from bokeh)\n",
            "Requirement already satisfied: six>=1.5.2 in /usr/local/lib/python3.6/dist-packages (from bokeh)\n",
            "Requirement already satisfied: tornado>=4.3 in /usr/local/lib/python3.6/dist-packages (from bokeh)\n",
            "Requirement already satisfied: MarkupSafe in /usr/local/lib/python3.6/dist-packages (from Jinja2>=2.7->bokeh)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging>=16.8->bokeh)\n",
            "Building wheels for collected packages: bokeh\n",
            "  Running setup.py bdist_wheel for bokeh ... \u001b[?25l-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \bdone\n",
            "\u001b[?25h  Stored in directory: /content/.cache/pip/wheels/0a/56/87/e8aaa58b05288bb4004cb11db4d502134552c996c0d84c0704\n",
            "Successfully built bokeh\n",
            "Installing collected packages: packaging, bokeh\n",
            "Successfully installed bokeh-0.12.15 packaging-17.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "IXqumQCHjK-m",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import os\n",
        "from random import shuffle\n",
        "import re\n",
        "from gensim.models import KeyedVectors\n",
        "import matplotlib.pyplot as plt\n",
        "import collections\n",
        "import time\n",
        "\n",
        "#%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "nsW48WM0lsbU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import urllib.request\n",
        "import zipfile\n",
        "import lxml.etree"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "lyWtvm39mbMf",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Step 1: Load data\n",
        "output:\n",
        "input_texts: list of 2085 talk transcriptions (entire text, not tokenized, mixed case, punctuation etc.)\n",
        "labels: corresponding list of 2085 strings containing several keywords each"
      ]
    },
    {
      "metadata": {
        "id": "zqJ-x3HYmYMI",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Download the dataset if it's not already there\n",
        "if not os.path.isfile('ted_en-20160408.zip'):\n",
        "    urllib.request.urlretrieve(\"https://wit3.fbk.eu/get.php?path=XML_releases/xml/ted_en-20160408.zip&filename=ted_en-20160408.zip\", filename=\"ted_en-20160408.zip\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ouftSvURms7-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# extract both the texts and the labels from the xml file\n",
        "with zipfile.ZipFile('ted_en-20160408.zip', 'r') as z:\n",
        "    doc = lxml.etree.parse(z.open('ted_en-20160408.xml', 'r'))\n",
        "texts = doc.xpath('//content/text()')\n",
        "labels = doc.xpath('//head/keywords/text()')\n",
        "del doc\n",
        "#print(input_texts[0])\n",
        "#print(labels[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "SzIcsZsnJFAK",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Download the dataset if it's not already there: this may take a minute as it is 75MB\n",
        "if not os.path.isfile('glove.6B.zip'):\n",
        "    urllib.request.urlretrieve(\"http://nlp.stanford.edu/data/glove.6B.zip\", filename=\"glove.6B.zip\")\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "A6MIy_vqKHxU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "88700e3e-5fb6-4402-9887-eb48a295a79f"
      },
      "cell_type": "code",
      "source": [
        "#!python -m zipfile -e glove.6B.zip z/\n",
        "#!python -m gensim.scripts.glove2word2vec --input z/glove.6B.50d.txt --output glove.6B.50d.w2vformat.txt"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/lib/python3.6/runpy.py:125: RuntimeWarning: 'gensim.scripts.glove2word2vec' found in sys.modules after import of package 'gensim.scripts', but prior to execution of 'gensim.scripts.glove2word2vec'; this may result in unpredictable behaviour\r\n",
            "  warn(RuntimeWarning(msg))\r\n",
            "2018-04-12 14:59:25,728 - glove2word2vec - INFO - running /usr/local/lib/python3.6/dist-packages/gensim/scripts/glove2word2vec.py --input z/glove.6B.50d.txt --output glove.6B.50d.w2vformat.txt\n",
            "2018-04-12 14:59:26,733 - glove2word2vec - INFO - converting 400000 vectors from z/glove.6B.50d.txt to glove.6B.50d.w2vformat.txt\n",
            "2018-04-12 14:59:27,632 - glove2word2vec - INFO - Converted model with 400000 vectors and 50 dimensions\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "b1IMG42gm072",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Step2: Preprocessing inputs and labels and building embeddings¶\n",
        "output:\n",
        "*  inputs_train: list of 1585 tuples of (token_list, label_integer) for training\n",
        "*  inputs_test: list of 250 tuples of (token_list, label_integer) for testing\n",
        "*  inputs_cv: list of 250 tuples of (token_list, label_integer) for cv"
      ]
    },
    {
      "metadata": {
        "id": "GFwBle3Nmyk-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "8c096de8-fcac-4db3-ad78-cc506679caeb"
      },
      "cell_type": "code",
      "source": [
        "# preprocess the texts: lowercase, remove text in parentheses, remove punctuation, tokenize into words (split on whitespace)\n",
        "#removing text in parentheses\n",
        "input_texts = [re.sub(r'\\([^)]*\\)', '', input_text) for input_text in texts]\n",
        "#lowercase\n",
        "input_texts = [input_text.lower() for input_text in input_texts]\n",
        "#remove punctuation\n",
        "input_texts = [re.sub(r'[^a-z0-9]+', ' ', input_text) for input_text in input_texts]\n",
        "#tokenize into words\n",
        "input_texts = [input_text.split() for input_text in input_texts]\n",
        "len(input_texts)\n",
        "#input_texts[0][:50]"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2085"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "metadata": {
        "id": "vTGwBwaknsS7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 398
        },
        "outputId": "f290f327-bdd3-4ce8-ccee-576973508e97"
      },
      "cell_type": "code",
      "source": [
        "#histogram over input lengths\n",
        "Y_plot, X_plot = np.histogram([len(text) for text in input_texts], bins=10)\n",
        "print(X_plot)\n",
        "X_plot = np.arange(10)\n",
        "plt.bar(X_plot, +Y_plot, facecolor='#9999ff', edgecolor='white')"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[   0.   671.5 1343.  2014.5 2686.  3357.5 4029.  4700.5 5372.  6043.5\n",
            " 6715. ]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Container object of 10 artists>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAeQAAAFKCAYAAADMuCxnAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nB7g/oaNbHdbwAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7f82b42bbba8>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "irGlk0xqnxlO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "12bbc26f-e1a9-4d35-dd2d-963522120265"
      },
      "cell_type": "code",
      "source": [
        "#get list of all words, and feed them into a Counter\n",
        "all_words = [word for input_text in input_texts for word in input_text]\n",
        "print(\"There are {} tokens in the dataset.\".format(len(all_words)))\n",
        "all_words_counter = collections.Counter(all_words)\n",
        "\n",
        "#remove some noise, take away the 100 most common and all words that only appear once\n",
        "most_common_50 = [word for word, count in all_words_counter.most_common(100)]\n",
        "only_once = [word for word, count in all_words_counter.most_common() if count == 1]\n",
        "print(\"There are {} tokens that appear only once.\".format(len(only_once)))\n",
        "\n",
        "to_remove = set(only_once + most_common_50)\n",
        "print(\"There are {} unique tokens to remove.\".format(len(to_remove)))\n",
        "\n",
        "start = time.time()\n",
        "input_texts = [[word for word in input_text if word not in to_remove] for input_text in input_texts]\n",
        "print(\"It took {} seconds to remove all unnecessary items.\".format(time.time()-start))\n",
        "\n",
        "new_all_words = [word for input_text in input_texts for word in input_text]\n",
        "print(\"There are now only {} tokens in the dataset.\".format(len(new_all_words)))\n",
        "\n",
        "#input_texts[0]"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There are 4474850 tokens in the dataset.\n",
            "There are 18438 tokens that appear only once.\n",
            "There are 18538 unique tokens to remove.\n",
            "It took 0.5699796676635742 seconds to remove all unnecessary items.\n",
            "There are now only 1926086 tokens in the dataset.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "NiJRjfINn4gA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d1db8370-2663-4bcb-dd8c-015974ecebe8"
      },
      "cell_type": "code",
      "source": [
        "#remove all inputs that have less than 500 tokens in them\n",
        "inputs = zip(input_texts, labels)\n",
        "inputs = [text_and_labels for text_and_labels in inputs if len(text_and_labels[0]) > 300]\n",
        "print(\"There are now only {} inputs left.\".format(len(inputs)))\n",
        "input_texts, labels = zip(*inputs)\n",
        "input_texts, labels = list(input_texts), list(labels)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There are now only 1924 inputs left.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "xCtahL_zoAUx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#padding every text to the max text length for later batching\n",
        "#l_max = max([len(text) for text in input_texts])\n",
        "#for text in input_texts:\n",
        "#    text += ['<zero_pad>'] * (l_max - len(text))\n",
        "\n",
        "#truncating every text to only the first 500 tokens\n",
        "l_max = 1000\n",
        "input_texts = [text[:l_max] for text in input_texts]\n",
        "input_texts = [(['<zero_pad>'] * (l_max - len(text)) + text) for text in input_texts]\n",
        "\n",
        "#print(input_texts[0][-10:-1])\n",
        "#print(np.mean([len(text) for text in input_texts]) == l_max)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "mBTKzR-CoEho",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "07714f24-8e8a-47e9-d1c2-5e493b282d13"
      },
      "cell_type": "code",
      "source": [
        "# preprocess the labels: search for occurences of the keywords \"technology\", \"entertainment\" or \"design\" and build labels\n",
        "label_lookup = ['ooo', 'Too', 'oEo', 'ooD', 'TEo', 'ToD', 'oED', 'TED']\n",
        "for i in range(len(labels)):\n",
        "    ted_labels = ['o', 'o', 'o']\n",
        "    keyword_list = labels[i].split(', ')\n",
        "    if 'technology' in keyword_list:\n",
        "        ted_labels[0] = 'T'\n",
        "    if 'entertainment' in keyword_list:\n",
        "        ted_labels[1] = 'E'\n",
        "    if 'design' in keyword_list:\n",
        "        ted_labels[2] = 'D'\n",
        "    labels[i] = ''.join(ted_labels)\n",
        "    labels[i] = label_lookup.index(labels[i])\n",
        "len(labels)\n",
        "labels[:20]"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0, 0, 0, 3, 5, 0, 0, 0, 0, 5, 0, 3, 2, 5, 0, 0, 3, 0, 5, 0]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "metadata": {
        "id": "l67udPf7oJFK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3b8b05b2-57eb-4d4a-ae84-7899c5e80f7a"
      },
      "cell_type": "code",
      "source": [
        "# creating the unique vocabulary lookup\n",
        "vocab_list = list(set([word for input_text in input_texts for word in input_text]))\n",
        "word_to_index = {}\n",
        "index_to_word = {}\n",
        "for i, word in enumerate(vocab_list):\n",
        "    word_to_index[word] = i\n",
        "    index_to_word[i] = word\n",
        "input_indices_list = []\n",
        "for input_text in input_texts:\n",
        "    input_indices_list.append([word_to_index[word] for word in input_text])\n",
        "len(vocab_list)\n",
        "#del vocab_list\n",
        "#del input_texts"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "35562"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "metadata": {
        "id": "QDK22z9XoNtY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#load glove word vectors\n",
        "glove = KeyedVectors.load_word2vec_format('glove.6B.50d.w2vformat.txt', binary=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "oFAcwmCfoRsf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "outputId": "49216652-3123-4448-8a26-e24dba0b34fd"
      },
      "cell_type": "code",
      "source": [
        "#creating embeddings, checking for each word in the input texts whether it is part of \n",
        "#the glove corpus, if yes intialize that row in the embeddings with the glove value, if\n",
        "#not initialize it uniformly between [-.1, .1]\n",
        "voc_len = len(word_to_index)\n",
        "print(\"vocabulary size: {} words\".format(voc_len))\n",
        "counter = 0\n",
        "not_found_list = []\n",
        "embeddings = np.random.uniform(-.1, .1, size=(voc_len, 50))\n",
        "for word, index in word_to_index.items():\n",
        "    if word in glove.vocab:\n",
        "        counter += 1\n",
        "        embeddings[index] = glove[word]\n",
        "    elif word == '<zero_pad>':\n",
        "        embeddings[index] = np.zeros(50)\n",
        "    else:\n",
        "        not_found_list.append(word)\n",
        "print(\"found {} word vectors, {} of our vocabulary\".format(counter, float(counter)/voc_len))\n",
        "print(\"missing words e.g. {}\".format(not_found_list[0:50]))"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "vocabulary size: 35562 words\n",
            "found 34558 word vectors, 0.9717676171193971 of our vocabulary\n",
            "missing words e.g. ['roadborne', 'unpicking', 'wasichu', 'eigenmodes', 'shhhhhhh', 'ebox', 'mazing', 'scvngr', 'cloudspotting', 'happinesses', 'barricelli', 'multicentric', 'shukran', 'whipcar', 'redditors', 'rewoven', 'lispenard', 'aquecer', 'rughal', 'wavebands', 'mansukh', 'shinerama', 'chiribiquete', 'hanifaru', 'biofluorescence', 'hackerspaces', 'flowerless', 'sekhri', 'whitopian', 'brakarz', 'electromechanics', 'pappists', 'matere', 'speras', 'femto', 'tedistan', 'cacilda', 'littlebits', 'tedmed', 'searchability', 'madantusi', 'sintia', 'disenthrall', 'decompiculture', 'temporariness', 'dimensionalize', 'pohnay', 'hyperscore', 'hyperconnected', 'enthrallment']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "tqnrl9z7CWPW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d92c6e32-ad1e-47e4-c982-e778f090ddb2"
      },
      "cell_type": "code",
      "source": [
        "# combining the tokens and labels for each input, then shuffle them and split into train/test/cv\n",
        "#inputs_combined = list(zip(input_indices_list, labels))\n",
        "#shuffle(inputs_combined)\n",
        "#inputs_train = inputs_combined[:1450]\n",
        "#inputs_test = inputs_combined[1450:1550]\n",
        "#inputs_cv = inputs_combined[1550:]\n",
        "#print((len(inputs_train), len(inputs_test), len(inputs_cv)))\n",
        "#print(inputs_train[0])\n",
        "#print([index_to_word[i] for i in inputs_train[0][0]])\n",
        "#print([input_pair[1] for input_pair in inputs_train])\n",
        "\n",
        "#keep the class label distribution intact\n",
        "inputs_combined = list(zip(input_indices_list, labels))\n",
        "inputs_train, inputs_test, inputs_cv = [], [], []\n",
        "for n in range(len(label_lookup)):\n",
        "    inputs_of_curr_class = [inpu for inpu in inputs_combined if inpu[1] == n]\n",
        "    l = len(inputs_of_curr_class)\n",
        "    split1 = round(0.8*l)\n",
        "    split2 = round(0.9*l)\n",
        "    inputs_train.extend(inputs_of_curr_class[:split1])\n",
        "    inputs_cv.extend(inputs_of_curr_class[split1:split2])\n",
        "    inputs_test.extend(inputs_of_curr_class[split2:])\n",
        "\n",
        "shuffle(inputs_train)\n",
        "shuffle(inputs_cv)\n",
        "shuffle(inputs_test)\n",
        "print((len(inputs_train), len(inputs_test), len(inputs_cv)))"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1540, 192, 192)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "MIdGmGPnX-RW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 347
        },
        "outputId": "f7ce2eef-29bf-49ca-a49a-c4ace5edd4cf"
      },
      "cell_type": "code",
      "source": [
        "#plotting a histogram over the label distribution in the entire dataset\n",
        "#as you can see 'ooo' is basically ~50% of the dataset, so an accuracy score\n",
        "#of 50% could be reached by simply learning to predict 'ooo' all the time (not good)\n",
        "Y_plot = np.histogram(labels, bins=8)[0]\n",
        "X_plot = np.arange(8)\n",
        "plt.bar(X_plot, +Y_plot, facecolor='#9999ff', edgecolor='white')\n",
        "for x,y in zip(X_plot,Y_plot):\n",
        "    plt.text(x, y+0.05, label_lookup[x], ha='center', va= 'bottom')"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAeoAAAFKCAYAAADScRzUAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7f82cd463f28>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "uFw-A0V1YHDO",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Step 3: Building the tensorflow model"
      ]
    },
    {
      "metadata": {
        "id": "KU2dGzBtYD3Q",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# building the tensorflow logistic regression model\n",
        "import tensorflow as tf"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "UwmgVjcsYnAc",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class TextClassifier(object):\n",
        "    def __init__(self, lr, activation, train_algo, embeddings, train_embeddings, voc_len, embed_size, batch_size, hidden_units, classes):\n",
        "        #placeholders\n",
        "        #(batch_size left)\n",
        "        self.input_ph = tf.placeholder(tf.int32, shape=(None, None), name='input')\n",
        "        self.labels_ph = tf.placeholder(tf.int32, shape=(None, classes), name='labels')\n",
        "        self.dropout_ph = tf.placeholder(tf.float32, shape=(), name='dropout')  \n",
        "        \n",
        "        #embedding layer\n",
        "        with tf.device('/cpu:0'), tf.name_scope(\"embedding\"):\n",
        "            #depending on whether a pre-trained embedding is provided and whether or not\n",
        "            #the embedding should be trainable\n",
        "            if embeddings is not None and train_embeddings is True:\n",
        "                self.L = tf.Variable(embeddings, name=\"L\")\n",
        "            elif embeddings is not None and train_embeddings is False:\n",
        "                self.L = tf.constant(embeddings, name=\"L\")\n",
        "            else:\n",
        "                self.L = tf.Variable(tf.random_uniform([voc_len, embed_size], -1.0, 1.0), name=\"L\")\n",
        "            input_vectors = tf.nn.embedding_lookup(self.L, self.input_ph)\n",
        "            X = tf.squeeze(tf.reduce_mean(input_vectors, axis=1, keep_dims=True), axis=1)\n",
        "        \n",
        "        #network model\n",
        "        with tf.name_scope(\"network\"):\n",
        "            W1 = tf.Variable(tf.random_normal((embed_size, hidden_units), stddev=0.1), name=\"W1\")\n",
        "            b1 = tf.Variable(tf.zeros(hidden_units), name='b1')\n",
        "\n",
        "            self.W2 = tf.Variable(tf.random_normal((hidden_units, classes), stddev=0.1), name=\"W2\")\n",
        "            b2 = tf.Variable(tf.zeros(classes), name='b2')\n",
        "            \n",
        "            if activation == 'relu':\n",
        "                hidden = tf.nn.relu(tf.matmul(tf.cast(X, tf.float32), W1) + b1)\n",
        "            elif activation == 'tanh':\n",
        "                hidden = tf.nn.tanh(tf.matmul(tf.cast(X, tf.float32), W1) + b1)\n",
        "            else:\n",
        "                hidden = tf.nn.sigmoid(tf.matmul(tf.cast(X, tf.float32), W1) + b1)\n",
        "            hidden = tf.nn.dropout(hidden, self.dropout_ph)\n",
        "\n",
        "            output = tf.matmul(hidden, self.W2) + b2\n",
        "            output = tf.nn.dropout(output, self.dropout_ph)\n",
        "            #yhat = tf.nn.softmax(out) #no need to calc whole prob dist if we only want the argmax\n",
        "            self.predictions = tf.argmax(output, axis=1)\n",
        "        \n",
        "        #loss\n",
        "        with tf.name_scope(\"loss\"):\n",
        "            self.losses = tf.nn.softmax_cross_entropy_with_logits(logits=output, labels=self.labels_ph)\n",
        "            l2_loss = tf.nn.l2_loss(W1) + tf.nn.l2_loss(b1) + tf.nn.l2_loss(self.W2) + tf.nn.l2_loss(b2)\n",
        "            self.loss = tf.reduce_mean(self.losses) + (0.01 * l2_loss)\n",
        "            \n",
        "        #acc\n",
        "        with tf.name_scope(\"accuracy\"):\n",
        "            correct_predictions = tf.equal(self.predictions, tf.argmax(self.labels_ph, axis=1))\n",
        "            self.accuracy = tf.reduce_mean(tf.cast(correct_predictions, tf.float32))\n",
        "            \n",
        "        #training operation\n",
        "        with tf.name_scope(\"training\"):\n",
        "            if train_algo == 'adam':\n",
        "                self.train_op = tf.train.AdamOptimizer(lr).minimize(self.loss)\n",
        "            elif train_algo == 'adagrad':\n",
        "                self.train_op = tf.train.AdagradOptimizer(lr).minimize(self.loss)\n",
        "            else:\n",
        "                self.train_op = tf.train.GradientDescentOptimizer(lr).minimize(self.loss)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "wuHJnYcpYtVg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class Trainer(object):\n",
        "    def __init__(self, nn, train_data, cv_data, test_data, batch_size, train_dropout, epochs):\n",
        "        self.nn = nn\n",
        "        self.train_data = train_data\n",
        "        self.cv_data = cv_data\n",
        "        self.test_data = test_data\n",
        "        self.batch_size = batch_size\n",
        "        self.train_dropout = train_dropout\n",
        "        self.epochs = epochs\n",
        "        self.W2, self.collect_preds, self.collect_truth = None, [], []\n",
        "\n",
        "    def _get_data_batch(self, curr_index, batch_size, data):\n",
        "        curr_batch = data[curr_index:curr_index+batch_size]\n",
        "        input_batch_list, labels_batch_list = zip(*curr_batch) #unzip the list of input pair tuples (text, label)\n",
        "        #print([len(text) for text in input_batch_list])\n",
        "        curr_input_batch = np.array(input_batch_list, dtype=np.int32)\n",
        "        one_hot = np.zeros((len(labels_batch_list), classes))            \n",
        "        one_hot[range(len(labels_batch_list)), labels_batch_list] = 1            \n",
        "        curr_labels_batch = one_hot\n",
        "        return curr_input_batch, curr_labels_batch\n",
        "    \n",
        "    def _print_status(self, i, epoch_loss, epoch_train_acc, epoch_cv_acc):\n",
        "        print (\"epoch: {}, epoch train loss: {:.3f}, epoch train accuracy: {:.3f}, epoch cv accuracy: {:.3f} \".\n",
        "               format(i, np.mean(epoch_loss), np.mean(epoch_train_acc), np.mean(epoch_cv_acc)))#, end=\"\\r\")\n",
        "        \n",
        "    def run_epoch(self, sess, i):\n",
        "        self.W2 = None\n",
        "        epoch_loss, epoch_train_acc, epoch_cv_acc = [], [], []\n",
        "        #run training on the train data\n",
        "        curr_index = 0\n",
        "        while curr_index < len(self.train_data):\n",
        "            curr_input_batch, curr_labels_batch = self._get_data_batch(curr_index, self.batch_size, self.train_data)\n",
        "            feed_dict={self.nn.dropout_ph:self.train_dropout, \n",
        "                       self.nn.input_ph:curr_input_batch, \n",
        "                       self.nn.labels_ph:curr_labels_batch}\n",
        "            self.W2, c_loss, c_losses, c_train_acc, _ = sess.run([self.nn.W2, self.nn.loss, self.nn.losses, self.nn.accuracy, self.nn.train_op], feed_dict=feed_dict)\n",
        "            #print(c_losses)\n",
        "            #print(c_loss)\n",
        "            epoch_loss.append(c_loss)\n",
        "            epoch_train_acc.append(c_train_acc)\n",
        "            curr_index += self.batch_size\n",
        "        \n",
        "        #run cross evaluation on the cv data\n",
        "        curr_index = 0\n",
        "        while curr_index < len(self.cv_data):\n",
        "            curr_input_batch, curr_labels_batch = self._get_data_batch(curr_index, self.batch_size, self.cv_data)\n",
        "            feed_dict={self.nn.dropout_ph:1.0, \n",
        "                       self.nn.input_ph:curr_input_batch, \n",
        "                       self.nn.labels_ph:curr_labels_batch}\n",
        "            c_cv_acc = sess.run(self.nn.accuracy, feed_dict=feed_dict)\n",
        "            epoch_cv_acc.append(c_cv_acc)\n",
        "            curr_index += self.batch_size\n",
        "        \n",
        "        self._print_status(i, epoch_loss, epoch_train_acc, epoch_cv_acc)\n",
        "    \n",
        "    def train(self):\n",
        "        print(\"Starting training for {} epochs.\".format(self.epochs))\n",
        "        with tf.Session() as sess:\n",
        "            tf.global_variables_initializer().run()\n",
        "            for i in range(self.epochs):\n",
        "                self.run_epoch(sess, i)\n",
        "            print(\"Done Training.\")\n",
        "            self._test(sess)\n",
        "        \n",
        "    def _test(self, sess):\n",
        "        print(\"Testing the trained model on the test set.\")\n",
        "        #would be better to choose the best model on cv for this instead of simply the one from the last iteration\n",
        "        curr_index = 0\n",
        "        epoch_test_acc = []\n",
        "        while curr_index < len(self.test_data):\n",
        "            curr_input_batch, curr_labels_batch = self._get_data_batch(curr_index, self.batch_size, self.test_data)\n",
        "            feed_dict={self.nn.dropout_ph:1.0, \n",
        "                       self.nn.input_ph:curr_input_batch, \n",
        "                       self.nn.labels_ph:curr_labels_batch}\n",
        "            c_test_acc, test_predictions = sess.run([self.nn.accuracy, self.nn.predictions], feed_dict=feed_dict)\n",
        "            epoch_test_acc.append(c_test_acc)\n",
        "            self.collect_preds.extend(test_predictions)\n",
        "            self.collect_truth.extend(np.argmax(curr_labels_batch, axis=1))\n",
        "            curr_index += self.batch_size\n",
        "        print(\"Test set accuracy: {}\".format(np.mean(epoch_test_acc)))\n",
        "        print(\"Done Testing.\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "BGIs6xZAY5z0",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Step 4: Model instantiation, training and testing"
      ]
    },
    {
      "metadata": {
        "id": "BCzedqH7Y3Zs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 629
        },
        "outputId": "9dfa4382-02fd-4945-b82a-b0244f4485ef"
      },
      "cell_type": "code",
      "source": [
        "#config\n",
        "embed_size = 50\n",
        "batch_size = 50\n",
        "hidden_units = 50\n",
        "learning_rate = 0.03\n",
        "voc_len = len(word_to_index)\n",
        "classes = len(label_lookup)\n",
        "\n",
        "\n",
        "#instantiate a network\n",
        "#this can now be tested with all kinds of configurations\n",
        "#'tanh', 'adam', dropout of 0.5 and a lr of 0.05 seems to work best for me\n",
        "nn = TextClassifier(\n",
        "    lr=learning_rate,\n",
        "    activation='tanh',\n",
        "    train_algo='adam',\n",
        "    embeddings=embeddings, #or embeddings=None\n",
        "    train_embeddings=True,\n",
        "    voc_len=voc_len,\n",
        "    embed_size=embed_size,\n",
        "    batch_size=batch_size,\n",
        "    hidden_units=hidden_units,\n",
        "    classes=classes\n",
        ")\n",
        "\n",
        "#instantiate a trainer, train the model on the train data and then run the test on the test data\n",
        "trainer = Trainer(\n",
        "    nn=nn,\n",
        "    train_data=inputs_train,\n",
        "    cv_data=inputs_cv,\n",
        "    test_data=inputs_test,\n",
        "    batch_size=batch_size,\n",
        "    train_dropout=0.5,\n",
        "    epochs=20\n",
        ")\n",
        "\n",
        "trainer.train()"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-45-58dcad93142f>:20: calling reduce_mean (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "keep_dims is deprecated, use keepdims instead\n",
            "WARNING:tensorflow:From <ipython-input-45-58dcad93142f>:45: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "\n",
            "Future major versions of TensorFlow will allow gradients to flow\n",
            "into the labels input on backprop by default.\n",
            "\n",
            "See tf.nn.softmax_cross_entropy_with_logits_v2.\n",
            "\n",
            "Starting training for 20 epochs.\n",
            "epoch: 0, epoch train loss: 1.821, epoch train accuracy: 0.470, epoch cv accuracy: 0.534 \n",
            "epoch: 1, epoch train loss: 1.606, epoch train accuracy: 0.562, epoch cv accuracy: 0.625 \n",
            "epoch: 2, epoch train loss: 1.513, epoch train accuracy: 0.627, epoch cv accuracy: 0.598 \n",
            "epoch: 3, epoch train loss: 1.424, epoch train accuracy: 0.675, epoch cv accuracy: 0.656 \n",
            "epoch: 4, epoch train loss: 1.314, epoch train accuracy: 0.723, epoch cv accuracy: 0.630 \n",
            "epoch: 5, epoch train loss: 1.315, epoch train accuracy: 0.722, epoch cv accuracy: 0.578 \n",
            "epoch: 6, epoch train loss: 1.262, epoch train accuracy: 0.739, epoch cv accuracy: 0.656 \n",
            "epoch: 7, epoch train loss: 1.264, epoch train accuracy: 0.742, epoch cv accuracy: 0.655 \n",
            "epoch: 8, epoch train loss: 1.218, epoch train accuracy: 0.757, epoch cv accuracy: 0.661 \n",
            "epoch: 9, epoch train loss: 1.213, epoch train accuracy: 0.764, epoch cv accuracy: 0.656 \n",
            "epoch: 10, epoch train loss: 1.221, epoch train accuracy: 0.753, epoch cv accuracy: 0.661 \n",
            "epoch: 11, epoch train loss: 1.190, epoch train accuracy: 0.759, epoch cv accuracy: 0.623 \n",
            "epoch: 12, epoch train loss: 1.174, epoch train accuracy: 0.768, epoch cv accuracy: 0.636 \n",
            "epoch: 13, epoch train loss: 1.151, epoch train accuracy: 0.772, epoch cv accuracy: 0.656 \n",
            "epoch: 14, epoch train loss: 1.132, epoch train accuracy: 0.780, epoch cv accuracy: 0.671 \n",
            "epoch: 15, epoch train loss: 1.154, epoch train accuracy: 0.773, epoch cv accuracy: 0.662 \n",
            "epoch: 16, epoch train loss: 1.158, epoch train accuracy: 0.772, epoch cv accuracy: 0.635 \n",
            "epoch: 17, epoch train loss: 1.103, epoch train accuracy: 0.799, epoch cv accuracy: 0.666 \n",
            "epoch: 18, epoch train loss: 1.129, epoch train accuracy: 0.795, epoch cv accuracy: 0.651 \n",
            "epoch: 19, epoch train loss: 1.127, epoch train accuracy: 0.782, epoch cv accuracy: 0.655 \n",
            "Done Training.\n",
            "Testing the trained model on the test set.\n",
            "Test set accuracy: 0.6476190686225891\n",
            "Done Testing.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "NTk3rLOYZXWM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 364
        },
        "outputId": "e2bd7b66-4ffc-4b28-c39f-44a48f1be21a"
      },
      "cell_type": "code",
      "source": [
        "bins = np.arange(9)\n",
        "plt.hist(np.array(trainer.collect_preds), bins, alpha=0.5, label='predictions')\n",
        "plt.hist(np.array(trainer.collect_truth), bins, alpha=0.5, label='truth')\n",
        "plt.legend(loc='upper right')"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7f82c57089e8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAeQAAAFKCAYAAADMuCxnAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nADAAgQwAgAEIZAAADEAgAwBggP8PWAKrWot4LZAAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7f82c5aaa5f8>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "187Rc7veZn1U",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "3b1ba341-cc3b-4458-ff3d-7feb11a0e544"
      },
      "cell_type": "code",
      "source": [
        "np.histogram(trainer.collect_truth, bins=8)"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([107,  37,  13,  15,   3,  12,   2,   3]),\n",
              " array([0.   , 0.875, 1.75 , 2.625, 3.5  , 4.375, 5.25 , 6.125, 7.   ]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "metadata": {
        "id": "L_Oj-htBZ0SR",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Step 5: Visualizing the hidden to output weight matrix"
      ]
    },
    {
      "metadata": {
        "id": "_7tucCJXZwLS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 47
        },
        "outputId": "e5128a6a-c49a-4e7b-8c15-2843e1d570d2"
      },
      "cell_type": "code",
      "source": [
        "from bokeh.models import ColumnDataSource, LabelSet\n",
        "from bokeh.plotting import figure, show, output_file\n",
        "from bokeh.io import output_notebook\n",
        "output_notebook()"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div class=\"bk-root\">\n",
              "        <a href=\"https://bokeh.pydata.org\" target=\"_blank\" class=\"bk-logo bk-logo-small bk-logo-notebook\"></a>\n",
              "        <span id=\"ea2df57b-3ade-4c72-ae7f-1f65e88c7c63\">Loading BokehJS ...</span>\n",
              "    </div>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "(function(root) {\n",
              "  function now() {\n",
              "    return new Date();\n",
              "  }\n",
              "\n",
              "  var force = true;\n",
              "\n",
              "  if (typeof (root._bokeh_onload_callbacks) === \"undefined\" || force === true) {\n",
              "    root._bokeh_onload_callbacks = [];\n",
              "    root._bokeh_is_loading = undefined;\n",
              "  }\n",
              "\n",
              "  var JS_MIME_TYPE = 'application/javascript';\n",
              "  var HTML_MIME_TYPE = 'text/html';\n",
              "  var EXEC_MIME_TYPE = 'application/vnd.bokehjs_exec.v0+json';\n",
              "  var CLASS_NAME = 'output_bokeh rendered_html';\n",
              "\n",
              "  /**\n",
              "   * Render data to the DOM node\n",
              "   */\n",
              "  function render(props, node) {\n",
              "    var script = document.createElement(\"script\");\n",
              "    node.appendChild(script);\n",
              "  }\n",
              "\n",
              "  /**\n",
              "   * Handle when an output is cleared or removed\n",
              "   */\n",
              "  function handleClearOutput(event, handle) {\n",
              "    var cell = handle.cell;\n",
              "\n",
              "    var id = cell.output_area._bokeh_element_id;\n",
              "    var server_id = cell.output_area._bokeh_server_id;\n",
              "    // Clean up Bokeh references\n",
              "    if (id !== undefined) {\n",
              "      Bokeh.index[id].model.document.clear();\n",
              "      delete Bokeh.index[id];\n",
              "    }\n",
              "\n",
              "    if (server_id !== undefined) {\n",
              "      // Clean up Bokeh references\n",
              "      var cmd = \"from bokeh.io.state import curstate; print(curstate().uuid_to_server['\" + server_id + \"'].get_sessions()[0].document.roots[0]._id)\";\n",
              "      cell.notebook.kernel.execute(cmd, {\n",
              "        iopub: {\n",
              "          output: function(msg) {\n",
              "            var element_id = msg.content.text.trim();\n",
              "            Bokeh.index[element_id].model.document.clear();\n",
              "            delete Bokeh.index[element_id];\n",
              "          }\n",
              "        }\n",
              "      });\n",
              "      // Destroy server and session\n",
              "      var cmd = \"import bokeh.io.notebook as ion; ion.destroy_server('\" + server_id + \"')\";\n",
              "      cell.notebook.kernel.execute(cmd);\n",
              "    }\n",
              "  }\n",
              "\n",
              "  /**\n",
              "   * Handle when a new output is added\n",
              "   */\n",
              "  function handleAddOutput(event, handle) {\n",
              "    var output_area = handle.output_area;\n",
              "    var output = handle.output;\n",
              "\n",
              "    // limit handleAddOutput to display_data with EXEC_MIME_TYPE content only\n",
              "    if ((output.output_type != \"display_data\") || (!output.data.hasOwnProperty(EXEC_MIME_TYPE))) {\n",
              "      return\n",
              "    }\n",
              "\n",
              "    var toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n",
              "\n",
              "    if (output.metadata[EXEC_MIME_TYPE][\"id\"] !== undefined) {\n",
              "      toinsert[toinsert.length - 1].firstChild.textContent = output.data[JS_MIME_TYPE];\n",
              "      // store reference to embed id on output_area\n",
              "      output_area._bokeh_element_id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n",
              "    }\n",
              "    if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n",
              "      var bk_div = document.createElement(\"div\");\n",
              "      bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n",
              "      var script_attrs = bk_div.children[0].attributes;\n",
              "      for (var i = 0; i < script_attrs.length; i++) {\n",
              "        toinsert[toinsert.length - 1].firstChild.setAttribute(script_attrs[i].name, script_attrs[i].value);\n",
              "      }\n",
              "      // store reference to server id on output_area\n",
              "      output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n",
              "    }\n",
              "  }\n",
              "\n",
              "  function register_renderer(events, OutputArea) {\n",
              "\n",
              "    function append_mime(data, metadata, element) {\n",
              "      // create a DOM node to render to\n",
              "      var toinsert = this.create_output_subarea(\n",
              "        metadata,\n",
              "        CLASS_NAME,\n",
              "        EXEC_MIME_TYPE\n",
              "      );\n",
              "      this.keyboard_manager.register_events(toinsert);\n",
              "      // Render to node\n",
              "      var props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n",
              "      render(props, toinsert[toinsert.length - 1]);\n",
              "      element.append(toinsert);\n",
              "      return toinsert\n",
              "    }\n",
              "\n",
              "    /* Handle when an output is cleared or removed */\n",
              "    events.on('clear_output.CodeCell', handleClearOutput);\n",
              "    events.on('delete.Cell', handleClearOutput);\n",
              "\n",
              "    /* Handle when a new output is added */\n",
              "    events.on('output_added.OutputArea', handleAddOutput);\n",
              "\n",
              "    /**\n",
              "     * Register the mime type and append_mime function with output_area\n",
              "     */\n",
              "    OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n",
              "      /* Is output safe? */\n",
              "      safe: true,\n",
              "      /* Index of renderer in `output_area.display_order` */\n",
              "      index: 0\n",
              "    });\n",
              "  }\n",
              "\n",
              "  // register the mime type if in Jupyter Notebook environment and previously unregistered\n",
              "  if (root.Jupyter !== undefined) {\n",
              "    var events = require('base/js/events');\n",
              "    var OutputArea = require('notebook/js/outputarea').OutputArea;\n",
              "\n",
              "    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n",
              "      register_renderer(events, OutputArea);\n",
              "    }\n",
              "  }\n",
              "\n",
              "  \n",
              "  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n",
              "    root._bokeh_timeout = Date.now() + 5000;\n",
              "    root._bokeh_failed_load = false;\n",
              "  }\n",
              "\n",
              "  var NB_LOAD_WARNING = {'data': {'text/html':\n",
              "     \"<div style='background-color: #fdd'>\\n\"+\n",
              "     \"<p>\\n\"+\n",
              "     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n",
              "     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n",
              "     \"</p>\\n\"+\n",
              "     \"<ul>\\n\"+\n",
              "     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n",
              "     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n",
              "     \"</ul>\\n\"+\n",
              "     \"<code>\\n\"+\n",
              "     \"from bokeh.resources import INLINE\\n\"+\n",
              "     \"output_notebook(resources=INLINE)\\n\"+\n",
              "     \"</code>\\n\"+\n",
              "     \"</div>\"}};\n",
              "\n",
              "  function display_loaded() {\n",
              "    var el = document.getElementById(\"ea2df57b-3ade-4c72-ae7f-1f65e88c7c63\");\n",
              "    if (el != null) {\n",
              "      el.textContent = \"BokehJS is loading...\";\n",
              "    }\n",
              "    if (root.Bokeh !== undefined) {\n",
              "      if (el != null) {\n",
              "        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n",
              "      }\n",
              "    } else if (Date.now() < root._bokeh_timeout) {\n",
              "      setTimeout(display_loaded, 100)\n",
              "    }\n",
              "  }\n",
              "\n",
              "\n",
              "  function run_callbacks() {\n",
              "    try {\n",
              "      root._bokeh_onload_callbacks.forEach(function(callback) { callback() });\n",
              "    }\n",
              "    finally {\n",
              "      delete root._bokeh_onload_callbacks\n",
              "    }\n",
              "    console.info(\"Bokeh: all callbacks have finished\");\n",
              "  }\n",
              "\n",
              "  function load_libs(js_urls, callback) {\n",
              "    root._bokeh_onload_callbacks.push(callback);\n",
              "    if (root._bokeh_is_loading > 0) {\n",
              "      console.log(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n",
              "      return null;\n",
              "    }\n",
              "    if (js_urls == null || js_urls.length === 0) {\n",
              "      run_callbacks();\n",
              "      return null;\n",
              "    }\n",
              "    console.log(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n",
              "    root._bokeh_is_loading = js_urls.length;\n",
              "    for (var i = 0; i < js_urls.length; i++) {\n",
              "      var url = js_urls[i];\n",
              "      var s = document.createElement('script');\n",
              "      s.src = url;\n",
              "      s.async = false;\n",
              "      s.onreadystatechange = s.onload = function() {\n",
              "        root._bokeh_is_loading--;\n",
              "        if (root._bokeh_is_loading === 0) {\n",
              "          console.log(\"Bokeh: all BokehJS libraries loaded\");\n",
              "          run_callbacks()\n",
              "        }\n",
              "      };\n",
              "      s.onerror = function() {\n",
              "        console.warn(\"failed to load library \" + url);\n",
              "      };\n",
              "      console.log(\"Bokeh: injecting script tag for BokehJS library: \", url);\n",
              "      document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
              "    }\n",
              "  };var element = document.getElementById(\"ea2df57b-3ade-4c72-ae7f-1f65e88c7c63\");\n",
              "  if (element == null) {\n",
              "    console.log(\"Bokeh: ERROR: autoload.js configured with elementid 'ea2df57b-3ade-4c72-ae7f-1f65e88c7c63' but no matching script tag was found. \")\n",
              "    return false;\n",
              "  }\n",
              "\n",
              "  var js_urls = [\"https://cdn.pydata.org/bokeh/release/bokeh-0.12.15.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-widgets-0.12.15.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-tables-0.12.15.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-gl-0.12.15.min.js\"];\n",
              "\n",
              "  var inline_js = [\n",
              "    function(Bokeh) {\n",
              "      Bokeh.set_log_level(\"info\");\n",
              "    },\n",
              "    \n",
              "    function(Bokeh) {\n",
              "      \n",
              "    },\n",
              "    function(Bokeh) {\n",
              "      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-0.12.15.min.css\");\n",
              "      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-0.12.15.min.css\");\n",
              "      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-widgets-0.12.15.min.css\");\n",
              "      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-widgets-0.12.15.min.css\");\n",
              "      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-tables-0.12.15.min.css\");\n",
              "      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-tables-0.12.15.min.css\");\n",
              "    }\n",
              "  ];\n",
              "\n",
              "  function run_inline_js() {\n",
              "    \n",
              "    if ((root.Bokeh !== undefined) || (force === true)) {\n",
              "      for (var i = 0; i < inline_js.length; i++) {\n",
              "        inline_js[i].call(root, root.Bokeh);\n",
              "      }if (force === true) {\n",
              "        display_loaded();\n",
              "      }} else if (Date.now() < root._bokeh_timeout) {\n",
              "      setTimeout(run_inline_js, 100);\n",
              "    } else if (!root._bokeh_failed_load) {\n",
              "      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n",
              "      root._bokeh_failed_load = true;\n",
              "    } else if (force !== true) {\n",
              "      var cell = $(document.getElementById(\"ea2df57b-3ade-4c72-ae7f-1f65e88c7c63\")).parents('.cell').data().cell;\n",
              "      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n",
              "    }\n",
              "\n",
              "  }\n",
              "\n",
              "  if (root._bokeh_is_loading === 0) {\n",
              "    console.log(\"Bokeh: BokehJS loaded, going straight to plotting\");\n",
              "    run_inline_js();\n",
              "  } else {\n",
              "    load_libs(js_urls, function() {\n",
              "      console.log(\"Bokeh: BokehJS plotting callback run at\", now());\n",
              "      run_inline_js();\n",
              "    });\n",
              "  }\n",
              "}(window));"
            ],
            "application/vnd.bokehjs_load.v0+json": "\n(function(root) {\n  function now() {\n    return new Date();\n  }\n\n  var force = true;\n\n  if (typeof (root._bokeh_onload_callbacks) === \"undefined\" || force === true) {\n    root._bokeh_onload_callbacks = [];\n    root._bokeh_is_loading = undefined;\n  }\n\n  \n\n  \n  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n    root._bokeh_timeout = Date.now() + 5000;\n    root._bokeh_failed_load = false;\n  }\n\n  var NB_LOAD_WARNING = {'data': {'text/html':\n     \"<div style='background-color: #fdd'>\\n\"+\n     \"<p>\\n\"+\n     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n     \"</p>\\n\"+\n     \"<ul>\\n\"+\n     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n     \"</ul>\\n\"+\n     \"<code>\\n\"+\n     \"from bokeh.resources import INLINE\\n\"+\n     \"output_notebook(resources=INLINE)\\n\"+\n     \"</code>\\n\"+\n     \"</div>\"}};\n\n  function display_loaded() {\n    var el = document.getElementById(\"ea2df57b-3ade-4c72-ae7f-1f65e88c7c63\");\n    if (el != null) {\n      el.textContent = \"BokehJS is loading...\";\n    }\n    if (root.Bokeh !== undefined) {\n      if (el != null) {\n        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n      }\n    } else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(display_loaded, 100)\n    }\n  }\n\n\n  function run_callbacks() {\n    try {\n      root._bokeh_onload_callbacks.forEach(function(callback) { callback() });\n    }\n    finally {\n      delete root._bokeh_onload_callbacks\n    }\n    console.info(\"Bokeh: all callbacks have finished\");\n  }\n\n  function load_libs(js_urls, callback) {\n    root._bokeh_onload_callbacks.push(callback);\n    if (root._bokeh_is_loading > 0) {\n      console.log(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n      return null;\n    }\n    if (js_urls == null || js_urls.length === 0) {\n      run_callbacks();\n      return null;\n    }\n    console.log(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n    root._bokeh_is_loading = js_urls.length;\n    for (var i = 0; i < js_urls.length; i++) {\n      var url = js_urls[i];\n      var s = document.createElement('script');\n      s.src = url;\n      s.async = false;\n      s.onreadystatechange = s.onload = function() {\n        root._bokeh_is_loading--;\n        if (root._bokeh_is_loading === 0) {\n          console.log(\"Bokeh: all BokehJS libraries loaded\");\n          run_callbacks()\n        }\n      };\n      s.onerror = function() {\n        console.warn(\"failed to load library \" + url);\n      };\n      console.log(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.getElementsByTagName(\"head\")[0].appendChild(s);\n    }\n  };var element = document.getElementById(\"ea2df57b-3ade-4c72-ae7f-1f65e88c7c63\");\n  if (element == null) {\n    console.log(\"Bokeh: ERROR: autoload.js configured with elementid 'ea2df57b-3ade-4c72-ae7f-1f65e88c7c63' but no matching script tag was found. \")\n    return false;\n  }\n\n  var js_urls = [\"https://cdn.pydata.org/bokeh/release/bokeh-0.12.15.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-widgets-0.12.15.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-tables-0.12.15.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-gl-0.12.15.min.js\"];\n\n  var inline_js = [\n    function(Bokeh) {\n      Bokeh.set_log_level(\"info\");\n    },\n    \n    function(Bokeh) {\n      \n    },\n    function(Bokeh) {\n      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-0.12.15.min.css\");\n      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-0.12.15.min.css\");\n      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-widgets-0.12.15.min.css\");\n      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-widgets-0.12.15.min.css\");\n      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-tables-0.12.15.min.css\");\n      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-tables-0.12.15.min.css\");\n    }\n  ];\n\n  function run_inline_js() {\n    \n    if ((root.Bokeh !== undefined) || (force === true)) {\n      for (var i = 0; i < inline_js.length; i++) {\n        inline_js[i].call(root, root.Bokeh);\n      }if (force === true) {\n        display_loaded();\n      }} else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(run_inline_js, 100);\n    } else if (!root._bokeh_failed_load) {\n      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n      root._bokeh_failed_load = true;\n    } else if (force !== true) {\n      var cell = $(document.getElementById(\"ea2df57b-3ade-4c72-ae7f-1f65e88c7c63\")).parents('.cell').data().cell;\n      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n    }\n\n  }\n\n  if (root._bokeh_is_loading === 0) {\n    console.log(\"Bokeh: BokehJS loaded, going straight to plotting\");\n    run_inline_js();\n  } else {\n    load_libs(js_urls, function() {\n      console.log(\"Bokeh: BokehJS plotting callback run at\", now());\n      run_inline_js();\n    });\n  }\n}(window));"
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "xz8ulKYpaWng",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from sklearn.manifold import TSNE\n",
        "tsne = TSNE(n_components=2, random_state=0)\n",
        "plot_W2 = tsne.fit_transform(trainer.W2.T)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vjS3-mPuaar_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "968b4ad4-e8f3-4692-dd13-5a49ceba6c6c"
      },
      "cell_type": "code",
      "source": [
        "label_lookup"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['ooo', 'Too', 'oEo', 'ooD', 'TEo', 'ToD', 'oED', 'TED']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "metadata": {
        "id": "5zVzQOVoaeyP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 647
        },
        "outputId": "1c53b5a5-7282-418c-b905-443bf0435257"
      },
      "cell_type": "code",
      "source": [
        "output_notebook()\n",
        "\n",
        "p = figure(tools=\"pan,wheel_zoom,reset,save\",\n",
        "           toolbar_location=\"above\",\n",
        "           title=\"word2vec T-SNE for most common words\")\n",
        "\n",
        "source = ColumnDataSource(data=dict(x1=plot_W2[:,0],\n",
        "                                    x2=plot_W2[:,1],\n",
        "                                    names=label_lookup))\n",
        "\n",
        "p.scatter(x=\"x1\", y=\"x2\", size=8, source=source)\n",
        "\n",
        "labels = LabelSet(x=\"x1\", y=\"x2\", text=\"names\", y_offset=6,\n",
        "                  text_font_size=\"8pt\", text_color=\"#555555\",\n",
        "                  source=source, text_align='center')\n",
        "p.add_layout(labels)\n",
        "\n",
        "show(p)"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div class=\"bk-root\">\n",
              "        <a href=\"https://bokeh.pydata.org\" target=\"_blank\" class=\"bk-logo bk-logo-small bk-logo-notebook\"></a>\n",
              "        <span id=\"009f6310-f60c-4e35-bb41-1a2ce67edfe7\">Loading BokehJS ...</span>\n",
              "    </div>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "(function(root) {\n",
              "  function now() {\n",
              "    return new Date();\n",
              "  }\n",
              "\n",
              "  var force = true;\n",
              "\n",
              "  if (typeof (root._bokeh_onload_callbacks) === \"undefined\" || force === true) {\n",
              "    root._bokeh_onload_callbacks = [];\n",
              "    root._bokeh_is_loading = undefined;\n",
              "  }\n",
              "\n",
              "  var JS_MIME_TYPE = 'application/javascript';\n",
              "  var HTML_MIME_TYPE = 'text/html';\n",
              "  var EXEC_MIME_TYPE = 'application/vnd.bokehjs_exec.v0+json';\n",
              "  var CLASS_NAME = 'output_bokeh rendered_html';\n",
              "\n",
              "  /**\n",
              "   * Render data to the DOM node\n",
              "   */\n",
              "  function render(props, node) {\n",
              "    var script = document.createElement(\"script\");\n",
              "    node.appendChild(script);\n",
              "  }\n",
              "\n",
              "  /**\n",
              "   * Handle when an output is cleared or removed\n",
              "   */\n",
              "  function handleClearOutput(event, handle) {\n",
              "    var cell = handle.cell;\n",
              "\n",
              "    var id = cell.output_area._bokeh_element_id;\n",
              "    var server_id = cell.output_area._bokeh_server_id;\n",
              "    // Clean up Bokeh references\n",
              "    if (id !== undefined) {\n",
              "      Bokeh.index[id].model.document.clear();\n",
              "      delete Bokeh.index[id];\n",
              "    }\n",
              "\n",
              "    if (server_id !== undefined) {\n",
              "      // Clean up Bokeh references\n",
              "      var cmd = \"from bokeh.io.state import curstate; print(curstate().uuid_to_server['\" + server_id + \"'].get_sessions()[0].document.roots[0]._id)\";\n",
              "      cell.notebook.kernel.execute(cmd, {\n",
              "        iopub: {\n",
              "          output: function(msg) {\n",
              "            var element_id = msg.content.text.trim();\n",
              "            Bokeh.index[element_id].model.document.clear();\n",
              "            delete Bokeh.index[element_id];\n",
              "          }\n",
              "        }\n",
              "      });\n",
              "      // Destroy server and session\n",
              "      var cmd = \"import bokeh.io.notebook as ion; ion.destroy_server('\" + server_id + \"')\";\n",
              "      cell.notebook.kernel.execute(cmd);\n",
              "    }\n",
              "  }\n",
              "\n",
              "  /**\n",
              "   * Handle when a new output is added\n",
              "   */\n",
              "  function handleAddOutput(event, handle) {\n",
              "    var output_area = handle.output_area;\n",
              "    var output = handle.output;\n",
              "\n",
              "    // limit handleAddOutput to display_data with EXEC_MIME_TYPE content only\n",
              "    if ((output.output_type != \"display_data\") || (!output.data.hasOwnProperty(EXEC_MIME_TYPE))) {\n",
              "      return\n",
              "    }\n",
              "\n",
              "    var toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n",
              "\n",
              "    if (output.metadata[EXEC_MIME_TYPE][\"id\"] !== undefined) {\n",
              "      toinsert[toinsert.length - 1].firstChild.textContent = output.data[JS_MIME_TYPE];\n",
              "      // store reference to embed id on output_area\n",
              "      output_area._bokeh_element_id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n",
              "    }\n",
              "    if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n",
              "      var bk_div = document.createElement(\"div\");\n",
              "      bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n",
              "      var script_attrs = bk_div.children[0].attributes;\n",
              "      for (var i = 0; i < script_attrs.length; i++) {\n",
              "        toinsert[toinsert.length - 1].firstChild.setAttribute(script_attrs[i].name, script_attrs[i].value);\n",
              "      }\n",
              "      // store reference to server id on output_area\n",
              "      output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n",
              "    }\n",
              "  }\n",
              "\n",
              "  function register_renderer(events, OutputArea) {\n",
              "\n",
              "    function append_mime(data, metadata, element) {\n",
              "      // create a DOM node to render to\n",
              "      var toinsert = this.create_output_subarea(\n",
              "        metadata,\n",
              "        CLASS_NAME,\n",
              "        EXEC_MIME_TYPE\n",
              "      );\n",
              "      this.keyboard_manager.register_events(toinsert);\n",
              "      // Render to node\n",
              "      var props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n",
              "      render(props, toinsert[toinsert.length - 1]);\n",
              "      element.append(toinsert);\n",
              "      return toinsert\n",
              "    }\n",
              "\n",
              "    /* Handle when an output is cleared or removed */\n",
              "    events.on('clear_output.CodeCell', handleClearOutput);\n",
              "    events.on('delete.Cell', handleClearOutput);\n",
              "\n",
              "    /* Handle when a new output is added */\n",
              "    events.on('output_added.OutputArea', handleAddOutput);\n",
              "\n",
              "    /**\n",
              "     * Register the mime type and append_mime function with output_area\n",
              "     */\n",
              "    OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n",
              "      /* Is output safe? */\n",
              "      safe: true,\n",
              "      /* Index of renderer in `output_area.display_order` */\n",
              "      index: 0\n",
              "    });\n",
              "  }\n",
              "\n",
              "  // register the mime type if in Jupyter Notebook environment and previously unregistered\n",
              "  if (root.Jupyter !== undefined) {\n",
              "    var events = require('base/js/events');\n",
              "    var OutputArea = require('notebook/js/outputarea').OutputArea;\n",
              "\n",
              "    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n",
              "      register_renderer(events, OutputArea);\n",
              "    }\n",
              "  }\n",
              "\n",
              "  \n",
              "  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n",
              "    root._bokeh_timeout = Date.now() + 5000;\n",
              "    root._bokeh_failed_load = false;\n",
              "  }\n",
              "\n",
              "  var NB_LOAD_WARNING = {'data': {'text/html':\n",
              "     \"<div style='background-color: #fdd'>\\n\"+\n",
              "     \"<p>\\n\"+\n",
              "     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n",
              "     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n",
              "     \"</p>\\n\"+\n",
              "     \"<ul>\\n\"+\n",
              "     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n",
              "     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n",
              "     \"</ul>\\n\"+\n",
              "     \"<code>\\n\"+\n",
              "     \"from bokeh.resources import INLINE\\n\"+\n",
              "     \"output_notebook(resources=INLINE)\\n\"+\n",
              "     \"</code>\\n\"+\n",
              "     \"</div>\"}};\n",
              "\n",
              "  function display_loaded() {\n",
              "    var el = document.getElementById(\"009f6310-f60c-4e35-bb41-1a2ce67edfe7\");\n",
              "    if (el != null) {\n",
              "      el.textContent = \"BokehJS is loading...\";\n",
              "    }\n",
              "    if (root.Bokeh !== undefined) {\n",
              "      if (el != null) {\n",
              "        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n",
              "      }\n",
              "    } else if (Date.now() < root._bokeh_timeout) {\n",
              "      setTimeout(display_loaded, 100)\n",
              "    }\n",
              "  }\n",
              "\n",
              "\n",
              "  function run_callbacks() {\n",
              "    try {\n",
              "      root._bokeh_onload_callbacks.forEach(function(callback) { callback() });\n",
              "    }\n",
              "    finally {\n",
              "      delete root._bokeh_onload_callbacks\n",
              "    }\n",
              "    console.info(\"Bokeh: all callbacks have finished\");\n",
              "  }\n",
              "\n",
              "  function load_libs(js_urls, callback) {\n",
              "    root._bokeh_onload_callbacks.push(callback);\n",
              "    if (root._bokeh_is_loading > 0) {\n",
              "      console.log(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n",
              "      return null;\n",
              "    }\n",
              "    if (js_urls == null || js_urls.length === 0) {\n",
              "      run_callbacks();\n",
              "      return null;\n",
              "    }\n",
              "    console.log(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n",
              "    root._bokeh_is_loading = js_urls.length;\n",
              "    for (var i = 0; i < js_urls.length; i++) {\n",
              "      var url = js_urls[i];\n",
              "      var s = document.createElement('script');\n",
              "      s.src = url;\n",
              "      s.async = false;\n",
              "      s.onreadystatechange = s.onload = function() {\n",
              "        root._bokeh_is_loading--;\n",
              "        if (root._bokeh_is_loading === 0) {\n",
              "          console.log(\"Bokeh: all BokehJS libraries loaded\");\n",
              "          run_callbacks()\n",
              "        }\n",
              "      };\n",
              "      s.onerror = function() {\n",
              "        console.warn(\"failed to load library \" + url);\n",
              "      };\n",
              "      console.log(\"Bokeh: injecting script tag for BokehJS library: \", url);\n",
              "      document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
              "    }\n",
              "  };var element = document.getElementById(\"009f6310-f60c-4e35-bb41-1a2ce67edfe7\");\n",
              "  if (element == null) {\n",
              "    console.log(\"Bokeh: ERROR: autoload.js configured with elementid '009f6310-f60c-4e35-bb41-1a2ce67edfe7' but no matching script tag was found. \")\n",
              "    return false;\n",
              "  }\n",
              "\n",
              "  var js_urls = [\"https://cdn.pydata.org/bokeh/release/bokeh-0.12.15.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-widgets-0.12.15.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-tables-0.12.15.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-gl-0.12.15.min.js\"];\n",
              "\n",
              "  var inline_js = [\n",
              "    function(Bokeh) {\n",
              "      Bokeh.set_log_level(\"info\");\n",
              "    },\n",
              "    \n",
              "    function(Bokeh) {\n",
              "      \n",
              "    },\n",
              "    function(Bokeh) {\n",
              "      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-0.12.15.min.css\");\n",
              "      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-0.12.15.min.css\");\n",
              "      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-widgets-0.12.15.min.css\");\n",
              "      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-widgets-0.12.15.min.css\");\n",
              "      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-tables-0.12.15.min.css\");\n",
              "      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-tables-0.12.15.min.css\");\n",
              "    }\n",
              "  ];\n",
              "\n",
              "  function run_inline_js() {\n",
              "    \n",
              "    if ((root.Bokeh !== undefined) || (force === true)) {\n",
              "      for (var i = 0; i < inline_js.length; i++) {\n",
              "        inline_js[i].call(root, root.Bokeh);\n",
              "      }if (force === true) {\n",
              "        display_loaded();\n",
              "      }} else if (Date.now() < root._bokeh_timeout) {\n",
              "      setTimeout(run_inline_js, 100);\n",
              "    } else if (!root._bokeh_failed_load) {\n",
              "      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n",
              "      root._bokeh_failed_load = true;\n",
              "    } else if (force !== true) {\n",
              "      var cell = $(document.getElementById(\"009f6310-f60c-4e35-bb41-1a2ce67edfe7\")).parents('.cell').data().cell;\n",
              "      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n",
              "    }\n",
              "\n",
              "  }\n",
              "\n",
              "  if (root._bokeh_is_loading === 0) {\n",
              "    console.log(\"Bokeh: BokehJS loaded, going straight to plotting\");\n",
              "    run_inline_js();\n",
              "  } else {\n",
              "    load_libs(js_urls, function() {\n",
              "      console.log(\"Bokeh: BokehJS plotting callback run at\", now());\n",
              "      run_inline_js();\n",
              "    });\n",
              "  }\n",
              "}(window));"
            ],
            "application/vnd.bokehjs_load.v0+json": "\n(function(root) {\n  function now() {\n    return new Date();\n  }\n\n  var force = true;\n\n  if (typeof (root._bokeh_onload_callbacks) === \"undefined\" || force === true) {\n    root._bokeh_onload_callbacks = [];\n    root._bokeh_is_loading = undefined;\n  }\n\n  \n\n  \n  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n    root._bokeh_timeout = Date.now() + 5000;\n    root._bokeh_failed_load = false;\n  }\n\n  var NB_LOAD_WARNING = {'data': {'text/html':\n     \"<div style='background-color: #fdd'>\\n\"+\n     \"<p>\\n\"+\n     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n     \"</p>\\n\"+\n     \"<ul>\\n\"+\n     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n     \"</ul>\\n\"+\n     \"<code>\\n\"+\n     \"from bokeh.resources import INLINE\\n\"+\n     \"output_notebook(resources=INLINE)\\n\"+\n     \"</code>\\n\"+\n     \"</div>\"}};\n\n  function display_loaded() {\n    var el = document.getElementById(\"009f6310-f60c-4e35-bb41-1a2ce67edfe7\");\n    if (el != null) {\n      el.textContent = \"BokehJS is loading...\";\n    }\n    if (root.Bokeh !== undefined) {\n      if (el != null) {\n        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n      }\n    } else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(display_loaded, 100)\n    }\n  }\n\n\n  function run_callbacks() {\n    try {\n      root._bokeh_onload_callbacks.forEach(function(callback) { callback() });\n    }\n    finally {\n      delete root._bokeh_onload_callbacks\n    }\n    console.info(\"Bokeh: all callbacks have finished\");\n  }\n\n  function load_libs(js_urls, callback) {\n    root._bokeh_onload_callbacks.push(callback);\n    if (root._bokeh_is_loading > 0) {\n      console.log(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n      return null;\n    }\n    if (js_urls == null || js_urls.length === 0) {\n      run_callbacks();\n      return null;\n    }\n    console.log(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n    root._bokeh_is_loading = js_urls.length;\n    for (var i = 0; i < js_urls.length; i++) {\n      var url = js_urls[i];\n      var s = document.createElement('script');\n      s.src = url;\n      s.async = false;\n      s.onreadystatechange = s.onload = function() {\n        root._bokeh_is_loading--;\n        if (root._bokeh_is_loading === 0) {\n          console.log(\"Bokeh: all BokehJS libraries loaded\");\n          run_callbacks()\n        }\n      };\n      s.onerror = function() {\n        console.warn(\"failed to load library \" + url);\n      };\n      console.log(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.getElementsByTagName(\"head\")[0].appendChild(s);\n    }\n  };var element = document.getElementById(\"009f6310-f60c-4e35-bb41-1a2ce67edfe7\");\n  if (element == null) {\n    console.log(\"Bokeh: ERROR: autoload.js configured with elementid '009f6310-f60c-4e35-bb41-1a2ce67edfe7' but no matching script tag was found. \")\n    return false;\n  }\n\n  var js_urls = [\"https://cdn.pydata.org/bokeh/release/bokeh-0.12.15.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-widgets-0.12.15.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-tables-0.12.15.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-gl-0.12.15.min.js\"];\n\n  var inline_js = [\n    function(Bokeh) {\n      Bokeh.set_log_level(\"info\");\n    },\n    \n    function(Bokeh) {\n      \n    },\n    function(Bokeh) {\n      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-0.12.15.min.css\");\n      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-0.12.15.min.css\");\n      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-widgets-0.12.15.min.css\");\n      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-widgets-0.12.15.min.css\");\n      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-tables-0.12.15.min.css\");\n      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-tables-0.12.15.min.css\");\n    }\n  ];\n\n  function run_inline_js() {\n    \n    if ((root.Bokeh !== undefined) || (force === true)) {\n      for (var i = 0; i < inline_js.length; i++) {\n        inline_js[i].call(root, root.Bokeh);\n      }if (force === true) {\n        display_loaded();\n      }} else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(run_inline_js, 100);\n    } else if (!root._bokeh_failed_load) {\n      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n      root._bokeh_failed_load = true;\n    } else if (force !== true) {\n      var cell = $(document.getElementById(\"009f6310-f60c-4e35-bb41-1a2ce67edfe7\")).parents('.cell').data().cell;\n      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n    }\n\n  }\n\n  if (root._bokeh_is_loading === 0) {\n    console.log(\"Bokeh: BokehJS loaded, going straight to plotting\");\n    run_inline_js();\n  } else {\n    load_libs(js_urls, function() {\n      console.log(\"Bokeh: BokehJS plotting callback run at\", now());\n      run_inline_js();\n    });\n  }\n}(window));"
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "<div class=\"bk-root\">\n",
              "    <div class=\"bk-plotdiv\" id=\"9a06f6c1-b570-47fa-bcfb-75d06154c8d6\"></div>\n",
              "</div>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "(function(root) {\n",
              "  function embed_document(root) {\n",
              "    \n",
              "  var docs_json = {\"096b2d54-1a1b-4d8b-b53e-faffb1fc029f\":{\"roots\":{\"references\":[{\"attributes\":{\"fill_alpha\":{\"value\":0.1},\"fill_color\":{\"value\":\"#1f77b4\"},\"line_alpha\":{\"value\":0.1},\"line_color\":{\"value\":\"#1f77b4\"},\"size\":{\"units\":\"screen\",\"value\":8},\"x\":{\"field\":\"x1\"},\"y\":{\"field\":\"x2\"}},\"id\":\"a22e09ca-edba-45ce-b08d-c149dae96a49\",\"type\":\"Circle\"},{\"attributes\":{\"formatter\":{\"id\":\"b04d20c2-73c5-40f9-acd0-e841d7035272\",\"type\":\"BasicTickFormatter\"},\"plot\":{\"id\":\"4a9a6bc7-74fb-4bce-933f-3f6794a93292\",\"subtype\":\"Figure\",\"type\":\"Plot\"},\"ticker\":{\"id\":\"b233081e-03a9-4ca5-b391-e8dba16c7086\",\"type\":\"BasicTicker\"}},\"id\":\"b09d9ab6-c146-459e-b0c8-563db6d1f865\",\"type\":\"LinearAxis\"},{\"attributes\":{\"below\":[{\"id\":\"0486b9be-a592-473a-9f9a-4dd0d95fbfb2\",\"type\":\"LinearAxis\"}],\"left\":[{\"id\":\"b09d9ab6-c146-459e-b0c8-563db6d1f865\",\"type\":\"LinearAxis\"}],\"renderers\":[{\"id\":\"0486b9be-a592-473a-9f9a-4dd0d95fbfb2\",\"type\":\"LinearAxis\"},{\"id\":\"83f93691-7511-490a-8dcb-63f395e8699c\",\"type\":\"Grid\"},{\"id\":\"b09d9ab6-c146-459e-b0c8-563db6d1f865\",\"type\":\"LinearAxis\"},{\"id\":\"425743dd-6dfc-44f8-a12e-8337fc92f799\",\"type\":\"Grid\"},{\"id\":\"c8c7513b-59ea-42f0-acc2-f19ac551518a\",\"type\":\"GlyphRenderer\"},{\"id\":\"2da077c7-d305-4291-a0d1-e3d6634c8bd5\",\"type\":\"LabelSet\"}],\"title\":{\"id\":\"68c303de-170f-4ccb-9c61-a5abd05edb34\",\"type\":\"Title\"},\"toolbar\":{\"id\":\"c85d972c-d39f-48c0-9c22-ac8611e647e4\",\"type\":\"Toolbar\"},\"toolbar_location\":\"above\",\"x_range\":{\"id\":\"bf234829-3e20-4587-b0a0-03b9267eb4fe\",\"type\":\"DataRange1d\"},\"x_scale\":{\"id\":\"d132d3c6-f350-402e-8173-a573a38ced1d\",\"type\":\"LinearScale\"},\"y_range\":{\"id\":\"a15608c6-f582-4240-aee2-a628ec787f19\",\"type\":\"DataRange1d\"},\"y_scale\":{\"id\":\"bcde46f7-5858-4477-b58f-c2baef3580f4\",\"type\":\"LinearScale\"}},\"id\":\"4a9a6bc7-74fb-4bce-933f-3f6794a93292\",\"subtype\":\"Figure\",\"type\":\"Plot\"},{\"attributes\":{},\"id\":\"cd790f35-d10b-40ec-8d72-8317f8a4cdd0\",\"type\":\"ResetTool\"},{\"attributes\":{},\"id\":\"bcde46f7-5858-4477-b58f-c2baef3580f4\",\"type\":\"LinearScale\"},{\"attributes\":{\"fill_color\":{\"value\":\"#1f77b4\"},\"line_color\":{\"value\":\"#1f77b4\"},\"size\":{\"units\":\"screen\",\"value\":8},\"x\":{\"field\":\"x1\"},\"y\":{\"field\":\"x2\"}},\"id\":\"7b8010f4-8abd-4743-9ccf-296743f9dd2b\",\"type\":\"Circle\"},{\"attributes\":{\"dimension\":1,\"plot\":{\"id\":\"4a9a6bc7-74fb-4bce-933f-3f6794a93292\",\"subtype\":\"Figure\",\"type\":\"Plot\"},\"ticker\":{\"id\":\"b233081e-03a9-4ca5-b391-e8dba16c7086\",\"type\":\"BasicTicker\"}},\"id\":\"425743dd-6dfc-44f8-a12e-8337fc92f799\",\"type\":\"Grid\"},{\"attributes\":{\"callback\":null},\"id\":\"bf234829-3e20-4587-b0a0-03b9267eb4fe\",\"type\":\"DataRange1d\"},{\"attributes\":{\"plot\":{\"id\":\"4a9a6bc7-74fb-4bce-933f-3f6794a93292\",\"subtype\":\"Figure\",\"type\":\"Plot\"},\"source\":{\"id\":\"acd713d2-e793-4b56-a061-3251b3101880\",\"type\":\"ColumnDataSource\"},\"text\":{\"field\":\"names\"},\"text_align\":\"center\",\"text_color\":{\"value\":\"#555555\"},\"text_font_size\":{\"value\":\"8pt\"},\"x\":{\"field\":\"x1\"},\"y\":{\"field\":\"x2\"},\"y_offset\":{\"value\":6}},\"id\":\"2da077c7-d305-4291-a0d1-e3d6634c8bd5\",\"type\":\"LabelSet\"},{\"attributes\":{},\"id\":\"06384b72-a456-4a4c-a7c8-20003e2a349f\",\"type\":\"WheelZoomTool\"},{\"attributes\":{\"active_drag\":\"auto\",\"active_inspect\":\"auto\",\"active_scroll\":\"auto\",\"active_tap\":\"auto\",\"tools\":[{\"id\":\"3775d03d-582b-4e1a-b6c5-4e94c0b0d289\",\"type\":\"PanTool\"},{\"id\":\"06384b72-a456-4a4c-a7c8-20003e2a349f\",\"type\":\"WheelZoomTool\"},{\"id\":\"cd790f35-d10b-40ec-8d72-8317f8a4cdd0\",\"type\":\"ResetTool\"},{\"id\":\"927b58e7-b838-4545-871c-5c7195bc2039\",\"type\":\"SaveTool\"}]},\"id\":\"c85d972c-d39f-48c0-9c22-ac8611e647e4\",\"type\":\"Toolbar\"},{\"attributes\":{\"formatter\":{\"id\":\"55594b1d-05bb-433f-b0de-d938dc9d1239\",\"type\":\"BasicTickFormatter\"},\"plot\":{\"id\":\"4a9a6bc7-74fb-4bce-933f-3f6794a93292\",\"subtype\":\"Figure\",\"type\":\"Plot\"},\"ticker\":{\"id\":\"e02f6791-454b-44c3-9c6b-706ea83e1dfd\",\"type\":\"BasicTicker\"}},\"id\":\"0486b9be-a592-473a-9f9a-4dd0d95fbfb2\",\"type\":\"LinearAxis\"},{\"attributes\":{},\"id\":\"d132d3c6-f350-402e-8173-a573a38ced1d\",\"type\":\"LinearScale\"},{\"attributes\":{\"callback\":null,\"column_names\":[\"x1\",\"x2\",\"names\"],\"data\":{\"names\":[\"ooo\",\"Too\",\"oEo\",\"ooD\",\"TEo\",\"ToD\",\"oED\",\"TED\"],\"x1\":{\"__ndarray__\":\"N9KIQUrTkkJ0RIJCRpAOQvGJncEtMArCNdxEQQW/S8I=\",\"dtype\":\"float32\",\"shape\":[8]},\"x2\":{\"__ndarray__\":\"APRcQodZ28Etm9tB0SOIwkGqf8Kn0AtCsbgIwbd3kME=\",\"dtype\":\"float32\",\"shape\":[8]}},\"selected\":null,\"selection_policy\":null},\"id\":\"acd713d2-e793-4b56-a061-3251b3101880\",\"type\":\"ColumnDataSource\"},{\"attributes\":{\"data_source\":{\"id\":\"acd713d2-e793-4b56-a061-3251b3101880\",\"type\":\"ColumnDataSource\"},\"glyph\":{\"id\":\"7b8010f4-8abd-4743-9ccf-296743f9dd2b\",\"type\":\"Circle\"},\"hover_glyph\":null,\"muted_glyph\":null,\"nonselection_glyph\":{\"id\":\"a22e09ca-edba-45ce-b08d-c149dae96a49\",\"type\":\"Circle\"},\"selection_glyph\":null,\"view\":{\"id\":\"4d989522-c4d8-4846-91c0-70c38366b599\",\"type\":\"CDSView\"}},\"id\":\"c8c7513b-59ea-42f0-acc2-f19ac551518a\",\"type\":\"GlyphRenderer\"},{\"attributes\":{},\"id\":\"b04d20c2-73c5-40f9-acd0-e841d7035272\",\"type\":\"BasicTickFormatter\"},{\"attributes\":{},\"id\":\"e02f6791-454b-44c3-9c6b-706ea83e1dfd\",\"type\":\"BasicTicker\"},{\"attributes\":{\"callback\":null},\"id\":\"a15608c6-f582-4240-aee2-a628ec787f19\",\"type\":\"DataRange1d\"},{\"attributes\":{},\"id\":\"b233081e-03a9-4ca5-b391-e8dba16c7086\",\"type\":\"BasicTicker\"},{\"attributes\":{\"source\":{\"id\":\"acd713d2-e793-4b56-a061-3251b3101880\",\"type\":\"ColumnDataSource\"}},\"id\":\"4d989522-c4d8-4846-91c0-70c38366b599\",\"type\":\"CDSView\"},{\"attributes\":{},\"id\":\"927b58e7-b838-4545-871c-5c7195bc2039\",\"type\":\"SaveTool\"},{\"attributes\":{\"plot\":{\"id\":\"4a9a6bc7-74fb-4bce-933f-3f6794a93292\",\"subtype\":\"Figure\",\"type\":\"Plot\"},\"ticker\":{\"id\":\"e02f6791-454b-44c3-9c6b-706ea83e1dfd\",\"type\":\"BasicTicker\"}},\"id\":\"83f93691-7511-490a-8dcb-63f395e8699c\",\"type\":\"Grid\"},{\"attributes\":{\"plot\":null,\"text\":\"word2vec T-SNE for most common words\"},\"id\":\"68c303de-170f-4ccb-9c61-a5abd05edb34\",\"type\":\"Title\"},{\"attributes\":{},\"id\":\"3775d03d-582b-4e1a-b6c5-4e94c0b0d289\",\"type\":\"PanTool\"},{\"attributes\":{},\"id\":\"55594b1d-05bb-433f-b0de-d938dc9d1239\",\"type\":\"BasicTickFormatter\"}],\"root_ids\":[\"4a9a6bc7-74fb-4bce-933f-3f6794a93292\"]},\"title\":\"Bokeh Application\",\"version\":\"0.12.15\"}};\n",
              "  var render_items = [{\"docid\":\"096b2d54-1a1b-4d8b-b53e-faffb1fc029f\",\"elementid\":\"9a06f6c1-b570-47fa-bcfb-75d06154c8d6\",\"modelid\":\"4a9a6bc7-74fb-4bce-933f-3f6794a93292\"}];\n",
              "  root.Bokeh.embed.embed_items_notebook(docs_json, render_items);\n",
              "\n",
              "  }\n",
              "  if (root.Bokeh !== undefined) {\n",
              "    embed_document(root);\n",
              "  } else {\n",
              "    var attempts = 0;\n",
              "    var timer = setInterval(function(root) {\n",
              "      if (root.Bokeh !== undefined) {\n",
              "        embed_document(root);\n",
              "        clearInterval(timer);\n",
              "      }\n",
              "      attempts++;\n",
              "      if (attempts > 100) {\n",
              "        console.log(\"Bokeh: ERROR: Unable to run BokehJS code because BokehJS library is missing\")\n",
              "        clearInterval(timer);\n",
              "      }\n",
              "    }, 10, root)\n",
              "  }\n",
              "})(window);"
            ],
            "application/vnd.bokehjs_exec.v0+json": ""
          },
          "metadata": {
            "tags": [],
            "application/vnd.bokehjs_exec.v0+json": {
              "id": "4a9a6bc7-74fb-4bce-933f-3f6794a93292"
            }
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "Tvm-T9XAZ_WS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "UhiOhZUySiq2",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Questions\n",
        "1. Influence of word embeddings (random init + train) vs. (glove init + train) vs. (glove init + fixed)?\n",
        "  * embeddings initialized with glove vectors and backpropagating into them was found to be the best variant with ~67% accuracy on the test set\n",
        "  * worst performance was random init and no backprop into the embeddings, this basically failed to learn anything which makes it clear that proper embeddings are very important for making sense out of text\n",
        "\n",
        "2. Performance for alternative activations (sigmoid, relu)?\n",
        "  * for the same parameters (hidden_units, dropout, etc.) the performance was actually tied between all three\n",
        "  * since the network is quite shallow it doesn't seem to play a big role in terms of vanishing or dying gradients so all three performed equally well (or bad if you look at the performance)\n",
        "\n",
        "3. What happens when you add dropout?\n",
        "  * dropout helps in reducing overfitting, the performance gap between the training and cv/test accuracy is now lower (~10%) which indicates a model that would be more able to generalize to new data\n",
        "4. Hidden layer size variation?\n",
        "  * does not seem to play a huge role if you start out on reasonable values\n",
        "  * since the embedding layer has a dimension of 50, the number of hidden units was also chosen to be 50 with the reasoning that it should at least be able to express the same information content as the embeddings\n",
        "  * much more than 50 didn't show significant differences in performance\n",
        "5. What to change for adding a second hidden layer?\n",
        "  * to add a second hidden layer in tensorflow is straightforward by simply defining two new variables (new weight and new bias) and copying the first hidden layer (linear transform -> activation)\n",
        "  * since 2 layers are still not really \"deep\" this should work with the same hyperparameters, however when adding even more layers one would have to take care of possible vanishing gradient issues\n",
        "6. Training algo influence?\n",
        "  * adam showed the best performance, however standard sgd was basically the same\n",
        "  * at first I thought it might be worth trying adagrad that might train better by being able to apply higher gradients into the word embeddings but it didn't turn out to be all that different to adam or sgd\n",
        "7. Graph is at the end of the notebook\n",
        "  * it seems like the weight embeddings for many of the labels that we failed to learn are lumped close together and also very close to the graph origin\n",
        "  * this indicates that we haven't really learned much about them and therefore fail to predict them\n",
        "\n",
        "#### Some insights\n",
        "* all texts were padded with a special token ('<PAD>') such that each sentence had exactly the length of the longest text in the dataset, this was important to get batching to work\n",
        "* as a sanity check it is worth thinking about the expected cross-entropy loss for a totally random model...since it is basically -log(yhat_max) for a one-hot ground truth vector, the expected value for 8 classes is -log(1/8) ~ 2.1 (so you should converge towards something significantly lower than that)\n",
        "* doing some more elaborate preprocessing (removing most frequent and least frequent words from the texts) really helps (i.e. removing noise) also because this removes a lot of the words that we didn't have a pretrained glove vector for\n",
        "* plotting the label predictions and the ground truth on the test set on top of each other makes it clear that there simply doesn't seem to be enough data for some of the labels"
      ]
    },
    {
      "metadata": {
        "id": "hhlTQzpKbfSS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 364
        },
        "outputId": "029cf791-d1ff-46e5-c5b6-fe5531dd4ae7"
      },
      "cell_type": "code",
      "source": [
        "bins = np.arange(9)\n",
        "plt.hist(np.array(trainer.collect_preds), bins, alpha=0.5, label='predictions')\n",
        "plt.hist(np.array(trainer.collect_truth), bins, alpha=0.5, label='truth')\n",
        "plt.legend(loc='upper right')"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7f82c39fe198>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAeQAAAFKCAYAAADMuCxnAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nADAAgQwAgAEIZAAADEAgAwBggP8PWAKrWot4LZAAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7f82c3b32438>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "EHBpesthbv9g",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "  *  the overall dataset is dominated by 50% of the label 'ooo' (neither T nor E nor D) with some labels only having around ~20 datapoints overall so there is really not much to learn from for our network and it is not surprising that it is very hard to predict especially those rare labels (see above cell 22)"
      ]
    }
  ]
}